{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for Adding `+` Operator to Model Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproccessing Pipeline and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "# Consider adding noise removal: https://stackoverflow.com/questions/62042172/how-to-remove-noise-in-image-opencv-python \n",
    "# @TODO Create pipeline for only contouring a single image at a time and multiple\n",
    "#\n",
    "# @brief Searches for contours inside image, the last contuor detected is returned.\n",
    "# @returns The pipeline returns the original digit with bounding box placed around it and also the contoured image.\n",
    "def preprocess_pipeline(img):\n",
    "\n",
    "  # Create Grayscale Copy and apply contours\n",
    "  grey = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
    "  ret, thresh = cv2.threshold(grey.copy(), 75, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "  contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  bounded_img = None\n",
    "  processed_digit = None\n",
    "\n",
    "  for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    \n",
    "    # Creating a rectangle around the digit in the original image (for displaying the digits fetched via contours)\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    # Save copy of bounded image\n",
    "    bounded_img = img\n",
    "    \n",
    "    # Cropping out the digit from the image corresponding to the current contours in the for loop\n",
    "    digit = thresh[y:y+h, x:x+w]\n",
    "    \n",
    "    # @todo create a ratio to better square a general image\n",
    "    # CHANGE NARROW OBJECTS TO SOON BE (18,18) PIXEL DIGIT\n",
    "    # HAND SCENARIO WHEN IMAGE IS NARROW; y pixel length is less than 10 pixels\n",
    "    x, y = digit.shape\n",
    "\n",
    "    padded_digit = digit.copy() # WHY THIS HERE\n",
    "\n",
    "    if (y < 10):\n",
    "        # Padd x-axis\n",
    "        difference = round((28 - y)/2)\n",
    "        padded_digit = np.pad(padded_digit, ((0,0),(difference,difference)),\"constant\", constant_values=0)\n",
    "\n",
    "    # Resize digit\n",
    "    resized_digit = cv2.resize(padded_digit, (18,18))\n",
    "    \n",
    "    # Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)\n",
    "    padded_digit = np.pad(resized_digit, ((5,5),(5,5)), \"constant\", constant_values=0)\n",
    "    \n",
    "    # Update image argument with processed form\n",
    "    processed_digit = padded_digit\n",
    "\n",
    "  return bounded_img, processed_digit\n",
    "\n",
    "\n",
    "# @TODO Consider new printing format since errors occur for certain\n",
    "#         lengths and images display too large.\n",
    "def display_list_of_images(images_list):\n",
    "  columns = 4\n",
    "\n",
    "  # if less than 10 images doesn't seem to print correctly\n",
    "  rows = math.ceil( len(images_list) / columns)\n",
    "\n",
    "  fig = plt.figure(figsize=(13,13))\n",
    "\n",
    "  for i in range(1, rows*columns - 1):\n",
    "    # Make prediction on each image before plotting\n",
    "    # prediction = model.predict(preprocessed_digits[i-1].reshape(1, 28, 28, 1))\n",
    "    p = fig.add_subplot(rows, columns, i)\n",
    "    # plt.xlabel('PREDICTION: {0}'.format(np.argmax(prediction)), fontsize=30)    \n",
    "    plt.imshow(images_list[i - 1], cmap='gray')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Save list of images to a specific folder\n",
    "# DOUBLE CHECK THIS METHOD BEFORE RUNNING AGAIN\n",
    "# maybe do read, rotate save images\n",
    "def read_rotate_save_images(images_folder, save_path, rotation, num_digits_return = 0):\n",
    "  image_file_names = os.listdir(images_folder)\n",
    "\n",
    "  # Create string of rotation to add to file name\n",
    "  rotatation_str = \"\"\n",
    "  if (rotation == 0):\n",
    "    rotatation_str = \"_c90\"\n",
    "  elif (rotation == 1):\n",
    "      rotatation_str = \"_c180\"\n",
    "  elif (rotation == 2):\n",
    "      rotatation_str = \"_c270\"\n",
    "\n",
    "  # Store 'num_digits_return' to return\n",
    "  rotated_digits = []\n",
    "\n",
    "  for i in range(0,len(image_file_names) - 1):\n",
    "    image = cv2.imread(images_folder+ image_file_names[i])\n",
    "\n",
    "    # 'rotation' expected is a cv2 rotation which is an int 0-2\n",
    "    # 0 is clockwise 90 degrees, 1 is 180, 2 is 90 counter clockwise\n",
    "    rotated_img = cv2.rotate(image, rotation)\n",
    "\n",
    "    if ( i < num_digits_return):\n",
    "      rotated_digits.append(rotated_img)\n",
    "\n",
    "    # Save image as its name plus how its rotated:\n",
    "    # Remove file type from img name\n",
    "    image_name = os.path.splitext(image_file_names[i])\n",
    "\n",
    "    cv2.imwrite(save_path + image_name[0] + rotatation_str +\".png\", rotated_img)\n",
    "\n",
    "  if (num_digits_return !=0 ):\n",
    "    return rotated_digits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Kaggle Dataset 567 Images of Hand Written `+` Wymbols\n",
    "- [Datatset Link](https://www.kaggle.com/datasets/sagyamthapa/handwritten-math-symbols),\n",
    "\"dataset/add\" is directory being added to model dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS #\n",
    "ORIGINAL_IMGS_PATH = \"./kaggle_dataset/add/\"\n",
    "IMGS_SAVE_PATH = \"./kaggle_dataset/add_preproc/\"\n",
    "NUM_DIGITS_DISPLAY = 2\n",
    "\n",
    "# Create folder to store rotated images:\n",
    "try: \n",
    "  os.mkdir(IMGS_SAVE_PATH)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "\n",
    "# Get list of all file names of images in kaggle_dataset/add\n",
    "image_names = os.listdir(ORIGINAL_IMGS_PATH)\n",
    "print(len(image_names))\n",
    "\n",
    "# Perform preprocessing on images from ORIGINAL_IMG_PATH\n",
    "preproc_digits = []\n",
    "for i in range(0,len(image_names)):\n",
    "  image = cv2.imread(ORIGINAL_IMGS_PATH + image_names[i])\n",
    "\n",
    "  # Create a image bounded from contour, then preprocess into (28, 28) image\n",
    "  bounded_img, preproc_img = preprocess_pipeline(image)\n",
    "\n",
    "  if (i < NUM_DIGITS_DISPLAY):\n",
    "    preproc_digits.append(bounded_img)\n",
    "    preproc_digits.append(preproc_img)\n",
    "\n",
    "  # Save preproc image to new folder\n",
    "  # save_img_to_add_preproc_dir(image_names[i],  preproc_img)\n",
    "  cv2.imwrite(IMGS_SAVE_PATH + image_names[i], preproc_img)\n",
    "\n",
    "\n",
    "# DISPLAYING IMAGES TO SEE OPERATION maybe display first 2?\n",
    "print(f\"DISPLAYING FIRST {NUM_DIGITS_DISPLAY} DIGITS\")\n",
    "display_list_of_images(preproc_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Duplicated Rotations of Preprocessed Images and Create Folder to Save Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ASLJDKFKSJDFKLJASDLKFSAD;LFKJASLKJDFSJDF\n",
    "\n",
    "# A@@@@@@@@@@@@ ADD GIT IGNORE TO DATASETS\n",
    "\n",
    "\n",
    "####SKDJFLKDJ AFKLSJD FKLAJ SDLKJFK;ASDF\n",
    "\n",
    "## GLOBALS\n",
    "## Create globals for save paths\n",
    "# INSURE NEW DIRECTORY IS WHATS USED FOR SAVE PATH\n",
    "ROTATED_IMAGES_SAVE_PATH = \"./full_+_preprocessed/\"\n",
    "PREPROCESSED_IMAGES_PATH = \"./kaggle_dataset/add_preproc/\"\n",
    "NUM_DIGITS_DISPLAY = 2\n",
    "\n",
    "# Create folder to store rotated images:\n",
    "try: \n",
    "  os.mkdir(ROTATED_IMAGES_SAVE_PATH)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# Create duplicate rotations of a folder and save rotated images\n",
    "rotation_list = [cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE]\n",
    "rotation_names = [\"ROTATE_90_CLOCKWISE\", \"ROTATE_180\", \"ROTATE_90_COUNTERCLOCKWISE\"]\n",
    "\n",
    "for rotation in rotation_list:\n",
    "  # read_rotate_save_images(images_folder, save_path, rotation, num_digits_return = 0):\n",
    "  saved_images = read_rotate_save_images(PREPROCESSED_IMAGES_PATH,\n",
    "    ROTATED_IMAGES_SAVE_PATH, rotation, NUM_DIGITS_DISPLAY)\n",
    "\n",
    "  # Display 20 saved images\n",
    "  print(f\"DISPLAYING FIRST {rotation_names[rotation]} DIGITS\")\n",
    "  display_list_of_images(saved_images)\n",
    "\n",
    "\n",
    "# Copy the original preprocessed digits into the newly created folder:\n",
    "image_names = os.listdir(PREPROCESSED_IMAGES_PATH)\n",
    "\n",
    "for i in range(0,len(image_names)):\n",
    "  image = cv2.imread(PREPROCESSED_IMAGES_PATH + image_names[i])\n",
    "\n",
    "  cv2.imwrite(ROTATED_IMAGES_SAVE_PATH + image_names[i], image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Processing Kaggle Dataset,5XX Images of Hand Written `+` Wymbols\n",
    "- [Datatset Link](https://www.kaggle.com/datasets/michelheusser/handwritten-digits-and-operators),\n",
    "\"All Data/+\" is directory being added to model dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "# GLOBALS #\n",
    "ORIGINAL_IMGS_PATH = \"./kaggle_dataset2/+/\"\n",
    "IMGS_SAVE_PATH = \"./kaggle_dataset2/+_preproc/\"\n",
    "NUM_DIGITS_DISPLAY = 2\n",
    "\n",
    "# Try to create a folder to store preprocessed images:\n",
    "try: \n",
    "  os.mkdir(IMGS_SAVE_PATH)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "\n",
    "image_names = os.listdir(ORIGINAL_IMGS_PATH)\n",
    "\n",
    "# Only the unprocessed images are going to be used from\n",
    "# this dataset, these images are determined using this regex\n",
    "regex_pattern = \"[+][_][\\d][_][\\d]+.png\"\n",
    "original_digits_names = []\n",
    "\n",
    "for file in image_names:\n",
    "  match = re.search(regex_pattern, file)\n",
    "\n",
    "  if match:\n",
    "    original_digits_names.append(file)\n",
    "\n",
    "\n",
    "preproc_digits = []\n",
    "for i in range(0,len(original_digits_names)):\n",
    "  image = cv2.imread(ORIGINAL_IMGS_PATH + original_digits_names[i])\n",
    "\n",
    "  # Creates copy of image then preprocesses copy\n",
    "  bounded_img, preproc_img = preprocess_pipeline(image)\n",
    "\n",
    "  if (i < NUM_DIGITS_DISPLAY):\n",
    "    preproc_digits.append(bounded_img)\n",
    "    preproc_digits.append(preproc_img)\n",
    "\n",
    "  # Save preproc image to new folder\n",
    "  cv2.imwrite(IMGS_SAVE_PATH + original_digits_names[i], preproc_img)\n",
    "\n",
    "\n",
    "# DISPLAYING IMAGES TO SEE OPERATION maybe display first 8?\n",
    "print(f\"DISPLAYING FIRST {NUM_DIGITS_DISPLAY} DIGITS\")\n",
    "display_list_of_images(preproc_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Duplicated Rotations of Preprocessed Images and Create Folder to Save Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "## GLOBALS\n",
    "## Create globals for save paths\n",
    "# INSURE NEW DIRECTORY IS WHATS USED FOR SAVE PATH\n",
    "ROTATED_IMAGES_SAVE_PATH = \"./full_+_preprocessed/\"\n",
    "PREPROCESSED_IMAGES_PATH = \"./kaggle_dataset2/+_preproc/\"\n",
    "NUM_DIGITS_DISPLAY = 2\n",
    "\n",
    "# Create folder to store rotated images:\n",
    "try: \n",
    "  os.mkdir(ROTATED_IMAGES_SAVE_PATH)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# Create duplicate rotations of a folder and save rotated images\n",
    "rotation_list = [cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE]\n",
    "rotation_names = [\"ROTATE_90_CLOCKWISE\", \"ROTATE_180\", \"ROTATE_90_COUNTERCLOCKWISE\"]\n",
    "\n",
    "for rotation in rotation_list:\n",
    "  # read_rotate_save_images(images_folder, save_path, rotation, num_digits_return = 0):\n",
    "  saved_images = read_rotate_save_images(PREPROCESSED_IMAGES_PATH,\n",
    "    ROTATED_IMAGES_SAVE_PATH, rotation, NUM_DIGITS_DISPLAY)\n",
    "\n",
    "  # Display 20 saved images\n",
    "  print(f\"DISPLAYING FIRST {rotation_names[rotation]} DIGITS\")\n",
    "  display_list_of_images(saved_images)\n",
    "\n",
    "\n",
    "# Copy the original preprocessed digits into the newly created folder:\n",
    "image_names = os.listdir(PREPROCESSED_IMAGES_PATH)\n",
    "\n",
    "for i in range(0,len(image_names)):\n",
    "  image = cv2.imread(PREPROCESSED_IMAGES_PATH + image_names[i])\n",
    "\n",
    "  cv2.imwrite(ROTATED_IMAGES_SAVE_PATH + image_names[i], image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create labels for all new images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/davidperez/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:316184)",
      "at w.execute (/Users/davidperez/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:315573)",
      "at w.start (/Users/davidperez/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:311378)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/davidperez/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:325786)",
      "at async t.CellExecutionQueue.start (/Users/davidperez/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:325326)"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_add_operator_dataset():\n",
    "\n",
    "  images_names = os.listdir(\"./full_+_preprocessed/\")\n",
    "  add_images = []\n",
    "  for img_name in images_names:\n",
    "    image = cv2.imread('./full_+_preprocessed/'+ img_name, 0)\n",
    "\n",
    "    add_images.append(image)\n",
    "\n",
    "  # Convert image to numpy array to match MNIST datatype\n",
    "  images = np.asarray(add_images)\n",
    "\n",
    "  # Load labels\n",
    "  image_labels = create_add_operator_labels()\n",
    "\n",
    "  # Convert labels to numpy array to match MNIST datatype\n",
    "  image_labels = np.asanyarray(image_labels)\n",
    "\n",
    "  # Remove 14% for test\n",
    "  # X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "  labels_frac = math.ceil(len(image_labels) * (1/7)) # >>> 604\n",
    "  images_test, images_train = images[:labels_frac] / 255., images[labels_frac:] / 255. \n",
    "  labels_test, labels_train = image_labels[:labels_frac] / 255., image_labels[labels_frac:] / 255. \n",
    "\n",
    "  # Take another 8% for validation set, remainder stays in train\n",
    "  labels_frac = math.ceil(len(image_labels) * (.5/6)) # >>> 353\n",
    "  images_valid, images_train = images[:labels_frac] / 255., images[labels_frac:] / 255. \n",
    "  labels_valid, labels_train = image_labels[:labels_frac] / 255., image_labels[labels_frac:] / 255. \n",
    "\n",
    "\n",
    "  print(\" @@@@@@@@@@@ Loc 1\")\n",
    "  print(\"img valie len\", len(images_valid))\n",
    "  print(\"labels valid new len\", len(labels_valid))\n",
    "\n",
    "\n",
    "  print(\"images_train shape: \", images_train.shape)\n",
    "  # print(\"train imgs\", len(images_train))\n",
    "  # print(\"test imgs\", len(images_test))\n",
    "  # print(\"val imgs\", len(images_valid))\n",
    "\n",
    "  return images_train, images_valid, images_test, labels_train, labels_valid, labels_test\n",
    "\n",
    "\n",
    "# Create float labels for every item in directory\n",
    "def create_add_operator_labels():\n",
    "  preprocessed_image_names = os.listdir(\"./full_+_preprocessed/\")\n",
    "  add_labels = 10\n",
    "  y_add_labels = [add_labels for img in range(len(preprocessed_image_names))]\n",
    "\n",
    "  return np.asarray(y_add_labels)\n",
    "\n",
    "# @brief Generate data subsets for neural net model.\n",
    "def create_mnist_train_test():\n",
    "  # number of images, 28x28 pixels\n",
    "  # Shape: X:(60000, 28, 28), Y:(10000, 28, 28)\n",
    "  (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "  print(type(X_train_full))\n",
    "  print(\"train_full len: \", len(X_train_full))\n",
    "\n",
    "  # Create validation set and convert to float in 0-1 range\n",
    "  X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "  y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "  X_test = X_test / 255.\n",
    "\n",
    "  # Append \n",
    "  # add_labels = create_add_operator_labels()\n",
    "  # can probably break this up to images then labels\n",
    "  add_train, add_valid, add_test, y_add_train, y_add_valid, y_add_test = load_add_operator_dataset()\n",
    "\n",
    "  print(\"mnist train shape: \", X_train.shape)\n",
    "\n",
    "  print(\" @@@@@@@@@@@\")\n",
    "  print(\"valid new len\", len(y_add_valid))\n",
    "  print(\"X_valid new len\", len(add_valid))\n",
    "\n",
    "\n",
    "  # Add add images to MNIST \n",
    "  X_train_new = np.concatenate((X_train, add_train))\n",
    "  X_test_new = np.concatenate((X_test, add_test))\n",
    "  X_valid_new = np.concatenate((X_valid, add_valid))\n",
    "  del add_train, add_valid, add_test\n",
    "  \n",
    "\n",
    "  y_train_new = np.concatenate((y_train, y_add_train))\n",
    "  y_valid_new = np.concatenate((y_valid, y_add_valid))\n",
    "  y_test_new = np.concatenate((y_test, y_add_test))\n",
    "  del y_add_train, y_add_valid, y_add_test\n",
    "\n",
    "  print(\" @@@@@@@@@@@\")\n",
    "  print(\"valid new len\", len(y_valid_new))\n",
    "  print(\"X_valid new len\", len(X_valid_new))\n",
    "\n",
    "  #@ TODO consider deleting old variables using the \"del\" command\n",
    "  print(\"new len\", len(y_train_new))\n",
    "\n",
    "  # Find shuffling algorithm to rearrange the add images and labels\n",
    "  idx = np.random.permutation(len(y_train_new))\n",
    "  X_train_new_sh, y_train_new_sh = X_train_new[idx], y_train_new[idx]\n",
    "\n",
    "  idx = np.random.permutation(len(y_valid_new))\n",
    "  X_valid_new_sh, y_valid_new_sh = X_valid_new[idx], y_valid_new[idx]\n",
    "\n",
    "  idx = np.random.permutation(len(y_test_new))\n",
    "  X_test_new_sh, y_test_new_sh = X_test_new[idx], y_test_new[idx]\n",
    "\n",
    "  # i = 0\n",
    "  # while (i < 10):\n",
    "  #   print(\"img index\", y_train_new_sh[55000 + i])\n",
    "  #   plt.imshow(X_train_new_sh[55000 + i])\n",
    "  #   plt.show()\n",
    "  #   i += 1\n",
    "\n",
    "\n",
    "  return  X_train_new_sh, X_valid_new_sh, X_test_new_sh, y_train_new_sh, y_valid_new_sh, y_test_new_sh\n",
    "\n",
    " # return X_train_new,  X_valid_new, X_test_new, y_train_new, y_valid_new, y_test_new\n",
    "\n",
    "# def mnist_labels_to_strs():\n",
    "\n",
    "#   preprocessed_image_names = os.listdir(\"./full_+_preprocessed/\")\n",
    "#   add_labels = (10 / 255.0)\n",
    "#   y_add_labels = [add_labels for img in range(len(preprocessed_image_names))]\n",
    "\n",
    "#   # Convering mnist dataset from numpy.uint8 to string\n",
    "#   y_train_str = y_train_full.astype(str)\n",
    "\n",
    "#   return   \n",
    "\n",
    "X_train,  X_valid, X_test, y_train, y_valid, y_test = create_mnist_train_test()\n",
    "\n",
    "# print(\"train len: \", len(X_train))\n",
    "# print(\"vali len: \", len(X_valid))\n",
    "# print(\"test len: \", len(X_test))\n",
    "\n",
    "\n",
    "\n",
    "### MAIN ###\n",
    "# (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# '0' parameter loads the color scale with image\n",
    "# Converts it to the shape of mnist (28, 28, 3) -> (28, 28)\n",
    "# image = cv2.imread(\"./full_+_preprocessed/+_1_0.png\", 0)\n",
    "\n",
    "\n",
    "# print(image.shape)\n",
    "\n",
    "# print(X_train_full[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "train_full len:  60000\n",
      " @@@@@@@@@@@ Loc 1\n",
      "img valie len 353\n",
      "labels valid new len 353\n",
      "images_train shape:  (3873, 28, 28)\n",
      "mnist train shape:  (55000, 28, 28)\n",
      "y[{i}] =  0 0.0392156862745098\n",
      "y_train[{i}] =  0 7\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_add_operator_dataset():\n",
    "\n",
    "  images_names = os.listdir(\"./full_+_preprocessed/\")\n",
    "  add_images = []\n",
    "  for img_name in images_names:\n",
    "    image = cv2.imread('./full_+_preprocessed/'+ img_name, 0)\n",
    "\n",
    "    add_images.append(image)\n",
    "\n",
    "  # Convert image to numpy array to match MNIST datatype\n",
    "  images = np.asarray(add_images)\n",
    "\n",
    "  # Load labels\n",
    "  image_labels = create_add_operator_labels()\n",
    "\n",
    "  # Convert labels to numpy array to match MNIST datatype\n",
    "  image_labels = np.asanyarray(image_labels)\n",
    "\n",
    "  # Remove 14% for test\n",
    "  # X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "  labels_frac = math.ceil(len(image_labels) * (1/7)) # >>> 604\n",
    "  images_test, images_train = images[:labels_frac] / 255., images[labels_frac:] / 255. \n",
    "  labels_test, labels_train = image_labels[:labels_frac], image_labels[labels_frac:] \n",
    "\n",
    "  # Take another 8% for validation set, remainder stays in train\n",
    "  labels_frac = math.ceil(len(image_labels) * (.5/6)) # >>> 353\n",
    "  images_valid, images_train = images[:labels_frac] / 255., images[labels_frac:] / 255. \n",
    "  labels_valid, labels_train = image_labels[:labels_frac], image_labels[labels_frac:] \n",
    "\n",
    "\n",
    "  print(\" @@@@@@@@@@@ Loc 1\")\n",
    "  print(\"img valie len\", len(images_valid))\n",
    "  print(\"labels valid new len\", len(labels_valid))\n",
    "\n",
    "\n",
    "  print(\"images_train shape: \", images_train.shape)\n",
    "  # print(\"train imgs\", len(images_train))\n",
    "  # print(\"test imgs\", len(images_test))\n",
    "  # print(\"val imgs\", len(images_valid))\n",
    "\n",
    "  return images_train, images_valid, images_test, labels_train, labels_valid, labels_test\n",
    "\n",
    "\n",
    "# Create float labels for every item in directory\n",
    "def create_add_operator_labels():\n",
    "  preprocessed_image_names = os.listdir(\"./full_+_preprocessed/\")\n",
    "  add_labels = 10\n",
    "  y_add_labels = [add_labels for img in range(len(preprocessed_image_names))]\n",
    "\n",
    "  return np.asarray(y_add_labels)\n",
    "\n",
    "# @brief Generate data subsets for neural net model.\n",
    "def create_mnist_train_test():\n",
    "  # number of images, 28x28 pixels\n",
    "  # Shape: X:(60000, 28, 28), Y:(10000, 28, 28)\n",
    "  (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "  print(type(X_train_full))\n",
    "  print(\"train_full len: \", len(X_train_full))\n",
    "\n",
    "  # Create validation set and convert to float in 0-1 range\n",
    "  X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "  y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "  X_test = X_test / 255.\n",
    "\n",
    "  # Append \n",
    "  # add_labels = create_add_operator_labels()\n",
    "  # can probably break this up to images then labels\n",
    "  add_train, add_valid, add_test, y_add_train, y_add_valid, y_add_test = load_add_operator_dataset()\n",
    "\n",
    "  print(\"mnist train shape: \", X_train.shape)\n",
    "\n",
    "  i = 0\n",
    "  print(\"y[{i}] = \",i,  y_add_train[i])\n",
    "  print(\"y_train[{i}] = \",i,  y_train[i])\n",
    "\n",
    "  # print(\" @@@@@@@@@@@\")\n",
    "  # print(\"valid new len\", len(y_add_valid))\n",
    "  # print(\"X_valid new len\", len(add_valid))\n",
    "\n",
    "\n",
    "  # # Add add images to MNIST \n",
    "  # X_train_new = np.concatenate((X_train, add_train))\n",
    "  # X_test_new = np.concatenate((X_test, add_test))\n",
    "  # X_valid_new = np.concatenate((X_valid, add_valid))\n",
    "  # del add_train, add_valid, add_test\n",
    "  \n",
    "\n",
    "  # y_train_new = np.concatenate((y_train, y_add_train))\n",
    "  # y_valid_new = np.concatenate((y_valid, y_add_valid))\n",
    "  # y_test_new = np.concatenate((y_test, y_add_test))\n",
    "  # del y_add_train, y_add_valid, y_add_test\n",
    "\n",
    "  # print(\" @@@@@@@@@@@\")\n",
    "  # print(\"valid new len\", len(y_valid_new))\n",
    "  # print(\"X_valid new len\", len(X_valid_new))\n",
    "\n",
    "  # #@ TODO consider deleting old variables using the \"del\" command\n",
    "  # print(\"new len\", len(y_train_new))\n",
    "\n",
    "  # # Find shuffling algorithm to rearrange the add images and labels\n",
    "  # idx = np.random.permutation(len(y_train_new))\n",
    "  # X_train_new_sh, y_train_new_sh = X_train_new[idx], y_train_new[idx]\n",
    "\n",
    "  # idx = np.random.permutation(len(y_valid_new))\n",
    "  # X_valid_new_sh, y_valid_new_sh = X_valid_new[idx], y_valid_new[idx]\n",
    "\n",
    "  # idx = np.random.permutation(len(y_test_new))\n",
    "  # X_test_new_sh, y_test_new_sh = X_test_new[idx], y_test_new[idx]\n",
    "\n",
    "\n",
    "  # return  X_train_new_sh, X_valid_new_sh, X_test_new_sh, y_train_new_sh, y_valid_new_sh, y_test_new_sh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ************ MAIN ************\n",
    "create_mnist_train_test()\n",
    "# X_train,  X_valid, X_test, y_train, y_valid, y_test = create_mnist_train_test()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add new operator images to dataset\n",
    "def add_images_to_dataset():\n",
    "\n",
    "  return\n",
    "\n",
    "# print(\"new label = \", y_add_labels[:8])\n",
    "# print(len(y_add_labels))\n",
    "# print(len(preprocessed_image_names))\n",
    "\n",
    "\n",
    "# #Before converting\n",
    "# print(\"import mnist: \", y_train_full)\n",
    "\n",
    "# # Convering mnist dataset from numpy.uint8 to string\n",
    "# y_train_str = y_train_full.astype(str)\n",
    "\n",
    "# print(\"mnist converted to string: \", y_train_str)\n",
    "\n",
    "# print(y_train_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Real World Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO Make a prediction method that returns an enum of the its prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "name": "python3915jvsc74a57bd04cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "metadata": {
   "interpreter": {
    "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}